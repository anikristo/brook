import numpy
from abc import ABCMeta

import tensorflow as tf


class IRGraph:
    def __init__(self, graph, input_node_names, output_node_names, prefix):

        self.flags = []

        self.PREFIX = prefix
        self.INPUT_NODE_NAMES = map(lambda x: prefix + '/' + x, input_node_names)
        self.OUTPUT_NODE_NAMES = map(lambda x: prefix + '/' + x, output_node_names)

        self._nodes = {}
        self.visited_op_names = set()
        self.input_node_names = []
        self.const_node_names = []

        self.graph = graph

        out_op = graph.get_operation_by_name(self.OUTPUT_NODE_NAMES[0])  # TODO: If more outputs?
        self.output_node = self._introspect_graph(out_op)

        self._resolve_constants()

        self._cleanup()

    def _add_node(self, op):
        """
        Adds a new node in the graph, if it doesn't exist yet

        :param op: The Op to be wrapped by an IRNode and added to the graph
        :return: The new IRNode generated by op
        :rtype: IRNode
        """
        if op.name not in self._nodes:
            if (op.type == 'Placeholder') and (op.name in self.INPUT_NODE_NAMES):
                node = IRInput(op)
                self._nodes[op.name] = node
                self.input_node_names.append(op.name)

            elif op.type == 'Const':
                node = IRConstant(op)
                self._nodes[op.name] = node
                self.const_node_names.append(op.name)

            else:
                node = IROp(op)
                self._nodes[op.name] = node
        else:
            node = self._nodes[op.name]
        return node

    def _get_successors(self, current_node):
        """
        Maps the list of successor names in the current_node to the actual IRNodes in the graph

        :param current_node: The node to be analyzed
        :type current_node: IRNode
        :return: The list of successor IRNodes for the given current_node
        :rtype: List[IRNode]
        """

        successor_nodes = []
        for p in current_node.successors:
            successor_nodes.append(self._nodes[p])

        return successor_nodes

    def _get_predecessors(self, current_node):
        """
        Maps the list of predecessor names in the current_node to the actual IRNodes in the graph

        :param current_node: The node to be analyzed
        :type current_node: IRNode
        :return: The list of predecessor IRNodes for the given current_node
        :rtype: List[IRNode]
        """

        predecessor_nodes = []
        for p in current_node.predecessors:
            predecessor_nodes.append(self._nodes[p])

        return predecessor_nodes

    def _set_predecessors(self, current_node, predecessors):
        """
        Assign predecessor nodes to current_node and, if they are not in the graph yet, continue introspection.

        :param current_node: Currently inspected node
        :type current_node: IRNode
        :param predecessors: A list of tensors that correspond to the inputs of current_node
        :type predecessors: List[tf.Tensor]
        :return: None
        """
        for tensor in predecessors:
            p_op = tensor._op
            current_node.add_predecessor(p_op.name)
            if p_op.name not in self._nodes:
                self._introspect_graph(p_op, current_node)

    def _introspect_graph(self, current_op, successor_node=None):
        """

        Introspection of the graph and generation of IRNodes to be added in IRGraph

        :param current_op: The currently inspected op
        :type current_op: tf.Operation
        :param successor_node: The next node in the graph execution order
        :type successor_node: IRNode
        :return: An IRNode that wraps current_op
        :rtype: IRNode
        """
        if current_op is None:
            raise Exception('Malformed graph')
        else:

            if current_op.type == 'Identity':
                current_node = self._add_node(current_op)
                self._set_predecessors(current_node, current_op._inputs)
                current_node.add_successor(successor_node.op.name)
                return current_node

            elif current_op.type == 'Placeholder':
                if current_op.name in self.INPUT_NODE_NAMES:
                    current_node = self._add_node(current_op)
                    current_node.add_successor(successor_node.op.name)
                    return current_node
                else:
                    raise Exception('Placeholders need to be declared as input nodes!. Aborting code generation.')

            elif current_op.type == 'Variable':
                raise Exception(
                    "Variable ops need to be converted to Constant before compilation! Make sure to use freeze_graph() "
                    + "beforehand. Aborting code generation.")

            elif current_op.type == 'Const':
                current_node = self._add_node(current_op)
                current_node.add_successor(successor_node.op.name)
                return current_node

            elif current_op.type == 'Add':
                current_node = self._add_node(current_op)
                if successor_node is not None:
                    current_node.add_successor(successor_node.op.name)
                self._set_predecessors(current_node, current_op._inputs)
                self.flags.append('FNCT_ADD')

                return current_node

            elif current_op.type == 'Sub':
                current_node = self._add_node(current_op)
                if successor_node is not None:
                    current_node.add_successor(successor_node.op.name)
                self._set_predecessors(current_node, current_op._inputs)
                self.flags.append('FNCT_SUB')

                return current_node

            elif current_op.type == 'Mul':
                current_node = self._add_node(current_op)
                if successor_node is not None:
                    current_node.add_successor(successor_node.op.name)
                self._set_predecessors(current_node, current_op._inputs)
                self.flags.append('FNCT_MUL')

                return current_node

            elif current_op.type == 'RealDiv':
                current_node = self._add_node(current_op)
                if successor_node is not None:
                    current_node.add_successor(successor_node.op.name)
                self._set_predecessors(current_node, current_op._inputs)
                self.flags.append('FNCT_DIV')

                return current_node

            elif current_op.type == 'MatMul':
                current_node = self._add_node(current_op)
                self._set_predecessors(current_node, current_op._inputs)
                if successor_node is not None:
                    current_node.add_successor(successor_node.op.name)

                return current_node

            elif current_op.type == 'Relu' or current_op.type == 'Relu6':
                current_node = self._add_node(current_op)
                self._set_predecessors(current_node, current_op._inputs)
                if successor_node is not None:
                    current_node.add_successor(successor_node.op.name)

                return current_node

            elif current_op.type == 'Maximum':
                current_node = self._add_node(current_op)
                self._set_predecessors(current_node, current_op._inputs)
                if successor_node is not None:
                    current_node.add_successor(successor_node.op.name)

                return current_node

            else:
                raise NotImplementedError('Unknown Operation: <' + current_op.type + '>. Aborting code generation.')

    def _resolve_constants(self):
        with tf.Session(graph=self.graph) as sess:
            for c in self.get_const_nodes():
                c.set_resolved_value(sess.run(c.get_output_tensor()))

    def _cleanup(self):
        """
        Cleans up the IR graph

        :return: None
        """
        self._cleanup_pass_1()
        self._cleanup_pass_2()

    def _cleanup_pass_1(self):
        """
       Removes Identity nodes from the graph. This also fixes the predecessor / successor
       dependencies after the removal.

       :return: None
       """
        to_be_deleted = []

        for k, v in self._nodes.iteritems():
            if k.endswith('/read') or v.op.type == 'Identity':
                # Get predecessors
                predecessors = self._get_predecessors(v)

                for p in predecessors:
                    p.set_successors(v.successors)
                    p.remove_successor(k)

                # Assign predecessors to current node's successors
                for successor in self._get_successors(v):
                    successor.predecessors.remove(k)  # TODO make these strings. Are they necessary after all???

                    for p in predecessors:
                        successor.add_predecessor(p.op.name)

                to_be_deleted.append(k)

        for k in to_be_deleted:
            # Remove from graph
            self._nodes.pop(k, None)

    def _cleanup_pass_2(self):
        """
        Detects and aborts if a constant op's resolved value is NaN

        :return: None
        """

        for k, v in self._nodes.iteritems():
            if (v.op.type == 'Const') and (v.get_resolved_value() is not None):
                if numpy.isnan(v.get_resolved_value()).any():
                    raise "A constant node (" + k + ") resolved to NaN. Aborting code generation."

    def get_const_nodes(self):
        return map(lambda x: self._nodes[x], self.const_node_names)

    def get_input_nodes(self):
        return map(lambda x: self._nodes[x], self.input_node_names)

    def get_output_nodes(self):
        return [self.output_node]  # TODO support multiple output nodes

    def get_node(self, name):
        if name in self._nodes:
            return self._nodes[name]


class IRNode(object):
    __metaclass__ = ABCMeta

    def __init__(self, op, predecessors=None, successors=None):
        if predecessors is None:
            self.predecessors = []
        if successors is None:
            self.successors = []
        self.op = op
        self.generated_code = None
        self.is_visited = False

    def get_variable_name(self):
        return self.op.name.lower().replace('/', '_')

    def add_successor(self, successor):
        self.successors.append(successor)

    def remove_successor(self, successor):
        self.successors.remove(successor)

    def set_successors(self, successors):
        self.successors.extend(successors)

    def add_predecessor(self, predecessor):
        self.predecessors.append(predecessor)

    def remove_predecessor(self, predecessor):
        self.predecessors.remove(predecessor)

    def get_type(self):
        return self.op.type


class IRConstant(IRNode):
    def __init__(self, op, predecessors=None, successors=None):
        IRNode.__init__(self, op, predecessors, successors)
        self.shape = None
        self.resolved_value = None
        self.is_scalar = False

    def get_output_tensor(self):
        return self.op.outputs[0]

    def get_resolved_value(self):
        return self.resolved_value

    def set_resolved_value(self, value):
        """

        Records the value of the tf.Constant ops

        :param value: The value obtained from the frozen graph
        :type value: ndarray
        :return: None
        """

        try:
            self.resolved_value = float(value)
            self.is_scalar = True
            self.shape = (1, 1)  # Dummy
        except TypeError:
            self.resolved_value = value
            self.shape = value.shape

            if len(self.shape) > 2:
                raise ValueError('High dimensional arrays are not supported!')

    def get_variable_name(self):
        if self.is_scalar:
            return self.resolved_value  # Propagates constants
        else:
            return super(IRConstant, self).get_variable_name()


class IRInput(IRNode):
    def __init__(self, op, predecessors=None, successors=None):
        IRNode.__init__(self, op, predecessors, successors)
        self.shape = None


class IROp(IRNode):
    def __init__(self, op, predecessors=None, successors=None):
        IRNode.__init__(self, op, predecessors, successors)
